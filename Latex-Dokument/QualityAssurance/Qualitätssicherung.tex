\documentclass[a4paper]{scrreprt}
\usepackage[german]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{pdflscape}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usepackage{bbding}
\usepackage{subfiles}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black, 
    urlcolor=black
}


\begin{document}
\title{Qualitätssicherungsdokument}
\author{Hanselmann, Hecht, Klein, Schnell, Stapelbroek, Wohnig}
\date{\today\\v0.4}
\maketitle 
\tableofcontents	

\chapter{Einleitung}


\chapter{Codereviews}

\section{Planung}
Wir haben die Qualitätssicherungsphase mit Codereviews angefangen.
Hierfür wurde unsere Gruppe in Gruppen zu je zwei Leuten unterteilt, wobei
darauf Wert gelegt wird, dass diese, die sich gegenseitig ihren Code erklären
müssen, möglichst wenig über den Code des anderen wissen. Wir haben hiermit
angefangen, um möglichst schnell die gröbsten Fehler im Code zu finden, sodass
wir uns im weiteren Verlauf des Qualitätssicherung auf versteckter liegende konzentrieren
konnten. Ein weiterer wichtiger Aspekt dieser Codereviwes war, den Code zu
refactorn, um die Lesbarkeit, Wartbarkeit und spätere Testbarkeit zu erhöhen.

\section{Ergebnis}
Das Ergebnis der Codereviews ist nicht ganz eindeutig. Während sie manchen
Personen geholfen haben Fehler zu finden, die beim späteren Testen
wahrscheinlich nicht entdeckt worden wären, und den Code an sich etwas robuster
zu machen, haben andere eigentlich nur ein paar Style Fehler gefunden, und
angegeben, dass ihnen die Codereviews eigentlich nicht geholfen hätten. Dies
kann aber auch daran gelegen haben, dass die Leute zu schnell über den Code
gegangen sind, und die andere Person nicht tiefgründig genug gehende Fragen
gestellt hat.

\chapter{Unit-Tests}

\section{Planung}
Neben den Codereviews haben wir anfangs parallel (zum
Beispiel weil ein Gruppenmitglied einer Zweiergruppe keine Zeit hat und sein
Partner etwas zu tun braucht) und später auch
verstärkt darauf hinarbeiten Testfälle für den Code zu schreiben.
Zum einen werden wir alle Testfälle, welche im Pflichtenheft genannt wurden,
implementieren. Sollte der Testfall GUI Bezug haben oder an sich nicht mit JUnit
realisieren lassen wird er dann von Hand ausgefürt. Dabei ist es jedoch wichtig alle Schritte genau zu
dokumentieren, damit der Test, im Falle einer Änderung, auch später noch
reproduzierbar ist.

\section{Übersicht über gefundene Fehler}
Dank der Unit-Tests und dem Testen von Hand konnten in dieser Phase  viele
Fehler gefunden werden, sodass wir hier eine Übersicht über einige geben werde:

\begin{itemize}
  \item Es gab einen Fehler in der Codegenerierung, sodass zum Beispiel Voting
  Arrays, die gleich sein sollten, unterschiedlich waren.
  \item In manchen Fälle ließ sich die Analyse nicht starten.
  \item Ein paar Nullpointer Exceptions.
  \item Die Ausgabe von CBMC konnte nicht immer richtig geparsed werden.
  \item Ein Fehler in der Codegenerierung, wenn man "`EXISTSONE"' verwendet.
  \item Fehler bei der Präferenz Wahl, bei der Wähler Kandidaten die selbe
  Position geben konnten.
\end{itemize}


\section{Testüberdeckung}
Zur Bewertung unserer Tests setzten wir als Metrik auf die
"`Instruktionsüberdeckung"', da sich diese am leichtesten messen lässt, und für
so ein komplexes Programm gut anzeigt, welche Bereiche noch weiterer Tests
bedürfen.
Weiterhin wird aber auch darauf geachtet, dass in den Methoden der einzelnen Klassen eine möglichst hohe
Pfadüberdeckung gegeben ist. Da die Metrik-Werkzeuge, welche wir verwenden zwar
nicht überdeckte Pfade anzeigen, daraus aber keine Ausdrucksvolle Metrik bauen
können, fließt sie nicht in die Metrik an sich mit ein, auch wenn darauf
geachtet wurde.
\newline
Momentan erreiche wir eine Testabdeckung von ca 77 \% (Stand 15.3.17 am Abend).
Für das fertige Dokument kommt hier ein Graph hin, in dem man die Testabdeckung
im Laufe der Zeit (mindestens zu jedem milestone) erkennen kann.

\section{Unit-Tests für AST- und Codegenerierung}
Da die theoretische Anzahl möglicher korrekter boolscher Ausdrücke abzählbar unendlich ist ist es unmöglich jeden möglichen Ausdruck auf korrekte Übersetzung in AST und C-Code zu überprüfen. Daher wird stattdessen die AST- und Codegenerierung jedes Sprachkonstrukts einmal auf Korrektheit überprüft. Sprachkonstrukte sind im Pflichtenheft in "'1.1 Die Syntax zur Angabe der formalen Eigenschaften"' beschrieben. Zusätzlich werden einige gängige komplexere Ausdrücke überprüft (Beispiele in https://formal.iti.kit.edu/teaching/pse/201617/voting/kickOff.pdf, Folie 22). Zur Überprüfung der ASTs wurde Funktionalität zur Darstellung eines ASTs in textueller Form implementiert. Diese Repräsentation wird auf Korrektheit überprüft. Die Codegenerierung wird so getestet, dass ein gegebener boolscher Ausdruck übersetzt wird. Dadurch wird bei der Überprüfung der Codegenerierung erneut die Erstellung der ASTs überprüft. 

\chapter{Performance und Verbrauch:}
Über die Phase haben wir unser Programm stetig in einem Profiler betrachtet, um
schnell reagieren zu können, sollte eine Änderung in dieser Phase die
Lauffähigkeit unseres Programmes stärker als Erwartet beeinflussen.
\newline
Die war jedoch nicht der Fall, sodass der Resoucenverbraucht vor und nach der
Qualitätssicherungsphase relativ konstant geblieben ist.
\newline
Wie man in \ref{fig1} und \ref{fig2} erkennen kann, ist der Verlauf des
Speicherverbrauches so gut wie identisch mit ca 30MB, bevor der "`garbage
collector"' es wieder auf ca 10 MB herunterbringt. Anscheinend haben viele
unserer Objekte nur eine kurze Lebensdauer, woraus sich auch schließen ließe,
dass unser Programm im "`Leerlauf"' einen insignifikanten Speicherverbrauch hat,
der Computersysteme von heute vor keine große Aufgabe stellen sollte.
\newline
Vergleicht man nun \ref{fig3} mit \ref{fig4} sieht man, dass sich die
Unterschiede der Versionen, während eine Eigenschaft überprüft wird, schon
stärker unterscheiden. Während der Arbeitsspeicherverbrauch zwar noch relativ
ähnlich zwischen den beiden Versionen ist, sieht man, dass die Auslastung des
Prozessors schon deutliche Unterschiede aufweist, welche jedoch vor allem darauf
zurückzuführen sind, dass nicht die exakt gleichen Wahlverfahren verglichen
wurden, da sich im Laufe der Qualitätssicherungsphase etwas am System zum
Speichern der Wahlverfahren geändert hatte.
\newline
Der Grund, aus dem der Resourcenverbrauch bei der Überprüfung so viel höher
liegt, ist, dass in dieser Phase zum einen der Code, welcher an CBMC gesendet
werden muss, für jede Eigenschaft einzeln erzeugt wird, und auch mehrere Threads
konstant die Ausgabe von CBMC auffangen müssen.
Ist die Überprüfung jedoch abgeschlossen normalisiert sich der
Resourcenverbrauch wieder relativ schnell.

\newpage
\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/OLD_NO.png} \caption{Dies ist der
  Resoucenverbrauch des Programmes, während es auf eine Eingabe vom Nutzer wartet und momentan keine Verifikation durchführt}
	\label{fig1}
\end{figure}

\vspace{4cm}

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/NEW_NO.png} \caption{Der Resourcenverbrauch der
  momentanten Version des Programmes, während keine Überprüfung durchgeführt wird}
	\label{fig2}
\end{figure}


\newpage

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.4\textwidth]{images/OLD_YES.png} \caption{Der Resourcenverbrauch
 der originalen Version von BEAST, während Eigenschaften überprüft werden}
	\label{fig3}
\end{figure}

\vspace{4cm}

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/NEW_YES.png} \caption{Der Resourcenverbrauch der
  momentanten Version des Programmes, während Eigenschaften überprüft werden}
	\label{fig4}
\end{figure}

\newpage
Betrachtet man die Verteilung der neusten BEAST Version während einer
Analyse (siehe \ref{fig5}) fällt auf, dass die Methoden, welche die meiste
Prozessorzeit in Anspruch nehmen, die sind, die dafür sorgen, dass das Programm
so angenehmt für wie möglich läuft. Würde man zum Beispiel die konstante
Überprüfung auf Fehler weniger häuftig ausführen, so müsste der Nutzer länger auf eine
Rückmeldung warten, was er noch ändern müsste. Ähnlich verhält es sich zu den
"`ThreadedBufferedReader"' Instanzen, die auch noch einen großen Anteil an der
Prozessorzeit haben. Dies liegt daran, dass sie die gesamte Kommunikation zu
außerhalb laufenden Prozessen übernehmen, und deshalb die gesamte Zeit ohne
Unterbrechung laufen müssen, solange der Prozess, den sie Überwachen, auch noch
läuft.

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/BEAST_PROCESSORTIME.png} \caption{Der
  Prozentuale Anteil einzelner Methoden an der gesamt benutzen Prozessorzeit}
	\label{fig5}
\end{figure}

\chapter{Fehlerbehebungen}

Nummer problem | Ursache | Lösung

Issue 16\\
Beschreibung: Es war möglich Zeilen zu verändern welche als nicht editierbar angezeigt und festgelegt wurden. Dies geschah wenn man unterhalb einer solchen Zeile etwas schrieb. Durch Entfernen des Zeilentrennungszeichens wurde dieses Zeichen dann in die nicht editierbare Zeile angehoben.\\
Lösung: In die \verb!removeToTheLeft! Methode in \verb!UserInserToCode! wurde ein zusätzlicher Check eingefügt. Es überprüft nun ob die Zeile über der, in welcher etwas gelöscht wird, nicht editierbar ist. Falls ja, und das zu löschende Zeichen ist ein Zeichentrennungszeichen, wird nur gelöscht falls die Zeile auf welcher sich der Cursor befindet leer ist.

Issue 27\\
Beschreibung: Obwohl als Voraussetzung angegeben war, dass beide vote-Arrays gleich sein sollten (\verb!VOTES1==VOTES2!) wurde in beiden Wahlvorgängen verschiedene Stimmen abgegeben.\\
Lösung: Der Bug stammte daher, dass der generierte Code die abgegebenen Stimmen nur bis zu Anzahl Wähler verglich. Bei Wahlverfahren, bei welchen jeder Wähler eine Liste von Länge Anzahl Kandidaten abgibt, wurden daher nur die ersten Stimmen verglichen. Dies führte zu dem Bug, sobald es mehr Kandidaten als Wähler gab.

Issue 28\\
Beschreibung: Bei einem Wahlverfahren welches Preference-Voting als input verwendet dauerte es enorm lange eine Eigenschaft zu testen, wenn es mehr Kandidaten als Wähler gab. Bei 6 Wählern und Kandidaten dauerte eine Überprüfung wenige Sekunden. Bei 5 Wählern und 6 Kandidaten war die Überprüfung nach 2 Minuten noch nicht fertig.\\
Lösung: Die Ursache war, dass bei Preference-voting als zusätzliche Voraussetzung alle von einem Wähler abgegebenen Stimmen verschieden sein müssen. Dies liegt daran dass diese Platzierungen von Wählern repräsentieren. Der Code welcher produziert wurde um diese Eigenschaft sicherzustellen war fehlerhaft.

Issue 42\\
Beschreibung: Bei der Codeerzeugung für Vergleiche wurden linke und rechte Seite des Vergleiches vertauscht.\\
Lösung: An der Stelle an welcher der String für den Vergleich generiert wird wurde lhs und rhs vertauscht. 
 


\chapter{Verbesserungen in der Phase}
Neben Fehlerbehebungen haben wir BEAST in dieser Phase auch in einigen Punkten
verbessert:

\begin{itemize}
  \item Im Eigenschafteneditor gibt es nun einen Knopf, welcher eine Erklärung
  über die BooleanExpressionLanguage gibt, mit der der Nutzer hier Befehler
  schreiben kann.
  \item Der Nutzer kann nun Wähler, Kandidaten und Sitze via ihrer Position in den entsprechenden Arrays angeben. Dazu wurden die Sprachkonstrukte \verb!VOTER_AT_POS!, \verb!CAND_AT_POS! und \verb!SEAT_AT_POS! implementiert.
  \item Der Nutzer kann nun beliebige mathematische Terme angeben, welche *, /, + und - unterstützen. Diese binären mathematischen Operationen können auf sämtliche Ausdrücke angewendet werden, welche einen ganzzahligen Wert liefern.
\end{itemize}

\chapter{Anhang}

\section{Testprotokolle}
\input{testProtokolle/Testfall8_1.tex}
\input{testProtokolle/Testfall8_1b.tex}
\input{testProtokolle/Testfall8_1c.tex}
\input{testProtokolle/Testfall8_2.tex}
\input{testProtokolle/Testfall8_4.tex}
\input{testProtokolle/Testfall8_5.tex}
\input{testProtokolle/Testfall8_6.tex}
\input{testProtokolle/Testfall8_7.tex}
\input{testProtokolle/Testfall8_8.tex}


\end{document}