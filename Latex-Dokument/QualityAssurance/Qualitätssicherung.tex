\documentclass[a4paper]{scrreprt}
\usepackage[german]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{pdflscape}
\usepackage{wrapfig}
\usepackage{adjustbox}
\usepackage{bbding}
\usepackage{subfiles}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black, 
    urlcolor=black
}


\begin{document}
\title{Qualitätssicherungsdokument}
\author{Hanselmann, Hecht, Klein, Schnell, Stapelbroek, Wohnig}
\date{\today\\v0.4}
\maketitle 
\tableofcontents	

\chapter{Einleitung}


\chapter{Codereviews}

\section{Planung}
Wir haben die Qualitätssicherungsphase mit Codereviews angefangen.
Hierfür wurde unsere Gruppe in Gruppen zu je zwei Leuten unterteilt, wobei
darauf Wert gelegt wurde, dass diese, die sich gegenseitig ihren Code erklären
müssen, möglichst wenig über den Code des anderen wissen. 

Wir haben hiermit
angefangen, um möglichst schnell die gröbsten Fehler im Code zu finden, sodass
wir uns im weiteren Verlauf der Qualitätssicherung auf versteckter liegende Fehler konzentrieren
konnten. Ein weiterer wichtiger Aspekt dieser Codereviews war, den Code zu
refactorn, um die Lesbarkeit, Wartbarkeit und spätere Testbarkeit zu erhöhen.

\section{Ergebnis}
Das Ergebnis der Codereviews ist nicht ganz eindeutig. Manchen
Teammitgliedern haben sie geholfen Fehler zu finden, die beim späteren Testen
wahrscheinlich nicht entdeckt worden wären, und den Code an sich etwas robuster
zu machen. Andere haben eigentlich nur ein paar Style-Fehler gefunden, und
angegeben, dass ihnen die Codereviews eigentlich nicht geholfen hätten. Dies
kann aber auch daran gelegen haben, dass die Leute zu schnell über den Code
gegangen sind, und die andere Person nicht genügend tiefgründige Fragen
gestellt hat.

\chapter{Unit-Tests}

\section{Planung}
Neben den Codereviews haben wir anfangs parallel (zum
Beispiel weil ein Gruppenmitglied einer Zweiergruppe keine Zeit hat und sein
Partner etwas zu tun braucht) und später auch
verstärkt darauf hingearbeitet, Testfälle für den Code zu schreiben.

Zum einen werden wir alle Testfälle, welche im Pflichtenheft genannt wurden,
implementieren. Sollte der Testfall GUI Bezug haben, oder sich überhaupt nicht mit JUnit
realisieren lassen, wird er dann von Hand ausgefürt. Dabei ist es jedoch wichtig alle Schritte genau zu
dokumentieren, damit der Test, im Falle einer Änderung, auch später noch
reproduzierbar ist.

\section{Übersicht über gefundene Fehler}
Dank der Unit-Tests und dem Testen von Hand konnten in dieser Phase viele
Fehler gefunden werden, sodass wir hier eine Übersicht über einige Fehler geben können:

\begin{itemize}
  \item Es gab einen Fehler in der Codegenerierung, sodass zum Beispiel Voting-Arrays, die gleich sein sollten, unterschiedlich waren.
  \item In manchen Fälle ließ sich die Analyse nicht starten.
  \item Ein paar Nullpointer-Exceptions.
  \item Die Ausgabe von CBMC konnte nicht immer richtig geparsed werden.
  \item Ein Fehler in der Codegenerierung, wenn man "`EXISTSONE"' verwendet.
  \item Fehler bei der Präferenz Wahl, bei der Wähler Kandidaten dieselbe
  Position geben konnten.
\end{itemize}


\section{Testüberdeckung}
Zur Bewertung unserer Tests setzten wir als Metrik auf die
"`Instruktionsüberdeckung"', da sich diese am leichtesten messen lässt, und für
so ein komplexes Programm gut anzeigt, welche Bereiche noch weiterer Tests
bedürfen.

Weiterhin wird aber auch darauf geachtet, dass in den Methoden der einzelnen Klassen eine möglichst hohe
Pfadüberdeckung gegeben ist. Da die Metrik-Werkzeuge, welche wir verwenden, zwar
nicht überdeckte Pfade anzeigen, sich daraus aber keine ausdrucksvolle Metrik ergibt, fließt sie nicht in die Metrik an sich mit ein, auch wenn darauf
geachtet wurde.

Momentan erreichen wir eine Testabdeckung von ca 77 \% (Stand 15.3.17 am Abend).
Für das fertige Dokument kommt hier ein Graph hin, in dem man die Testabdeckung
im Laufe der Zeit (mindestens zu jedem Meilenstein) erkennen kann.

\section{Unit-Tests für AST- und Codegenerierung}
Da die theoretische Anzahl möglicher korrekter boolscher Ausdrücke abzählbar unendlich ist, ist es unmöglich jeden möglichen Ausdruck auf korrekte Übersetzung in AST und C-Code zu überprüfen. Daher wird stattdessen die AST- und Codegenerierung jedes Sprachkonstrukts einmal auf Korrektheit überprüft. 

Sprachkonstrukte sind im Pflichtenheft in "'1.1 Die Syntax zur Angabe der formalen Eigenschaften"' beschrieben. Zusätzlich werden einige gängige komplexere Ausdrücke überprüft (Beispiele in https://formal.iti.kit.edu/teaching/pse/201617/voting/kickOff.pdf, Folie 22). 

Zur Überprüfung der ASTs wurde Funktionalität zur Darstellung eines ASTs in textueller Form implementiert. Diese Repräsentation wird auf Korrektheit überprüft. Die Codegenerierung wird so getestet, dass ein gegebener boolscher Ausdruck übersetzt wird. Dadurch wird bei der Überprüfung der Codegenerierung erneut die Erstellung der ASTs überprüft. 

\chapter{Performance und Verbrauch:}
Über die Phase hinweg haben wir unser Programm stetig in einem Profiler betrachtet, um
schnell reagieren zu können, sollte eine Änderung in dieser Phase die
Lauffähigkeit unseres Programmes stärker als erwartet beeinflussen.

Das war jedoch nicht der Fall, sodass der Ressourcenverbrauch vor und nach der
Qualitätssicherungsphase relativ konstant geblieben ist.

Wie man in \ref{fig1} und \ref{fig2} erkennen kann, ist der Verlauf des
Speicherverbrauches so gut wie identisch mit ca. 30MB, bevor der "`garbage
collector"' es wieder auf ca. 10 MB herunterbringt. Anscheinend haben viele
unserer Objekte nur eine kurze Lebensdauer, woraus sich auch schließen ließe,
dass unser Programm im "`Leerlauf"' einen insignifikanten Speicherverbrauch hat,
der Computersysteme von heute vor keine große Aufgabe stellen sollte.

Vergleicht man nun \ref{fig3} mit \ref{fig4} sieht man, dass sich die
Unterschiede der Versionen, während eine Eigenschaft überprüft wird, schon
stärker unterscheiden. Während der Arbeitsspeicherverbrauch zwar noch relativ
ähnlich zwischen den beiden Versionen ist, sieht man, dass die Auslastung des
Prozessors schon deutliche Unterschiede aufweist. Diese Unterschiede sind jedoch vor allem darauf
zurückzuführen, dass nicht die exakt gleichen Wahlverfahren verglichen
wurden, weil sich im Laufe der Qualitätssicherungsphase etwas am System zum
Speichern der Wahlverfahren geändert hatte.

Der Grundfür den höheren Ressourcenverbrauch bei der Überprüfung ist, dass in dieser Phase zum einen der Code, welcher an CBMC gesendet
werden muss, für jede Eigenschaft einzeln erzeugt wird. Auch müssen mehrere Threads
konstant die Ausgabe von CBMC auffangen.
Ist die Überprüfung jedoch abgeschlossen normalisiert sich der
Ressourcenverbrauch wieder relativ schnell.

\newpage
\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/OLD_NO.png} \caption{Dies ist der
  Ressourcenverbrauch des Programmes, während es auf eine Eingabe vom Nutzer wartet und momentan keine Verifikation durchführt}
	\label{fig1}
\end{figure}

\vspace{4cm}

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/NEW_NO.png} \caption{Der Ressourcenverbrauch der
  momentanen Version des Programmes, während keine Überprüfung durchgeführt wird}
	\label{fig2}
\end{figure}


\newpage

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.4\textwidth]{images/OLD_YES.png} \caption{Der Ressourcenverbrauch
 der originalen Version von BEAST, während Eigenschaften überprüft werden}
	\label{fig3}
\end{figure}

\vspace{4cm}

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/NEW_YES.png} \caption{Der Ressourcenverbrauch der
  momentanen Version des Programmes, während Eigenschaften überprüft werden}
	\label{fig4}
\end{figure}

\newpage
Betrachtet man die Verteilung der Prozessorzeit der neusten BEAST-Version während einer
Analyse (siehe \ref{fig5}) fällt auf, dass die Methoden, welche die meiste
Zeit in Anspruch nehmen, die sind, die dafür sorgen, dass das Programm
so angenehm wie möglich läuft. Würde man zum Beispiel die konstante
Überprüfung auf Fehler weniger häufig ausführen, müsste der Nutzer länger auf eine
Rückmeldung warten, was er noch ändern müsste. 

Ähnlich verhält es sich zu den
"`ThreadedBufferedReader"'-Instanzen, die auch noch einen großen Anteil an der
Prozessorzeit haben. Dies liegt daran, dass sie die gesamte Kommunikation zu
außerhalb laufenden Prozessen übernehmen, und deshalb die gesamte Zeit ohne
Unterbrechung laufen müssen, solange der Prozess, den sie überwachen, auch noch
läuft.

\begin{figure}[ht]
	\centering
  \includegraphics[width=1.0\textwidth,
  height=0.40\textwidth]{images/BEAST_PROCESSORTIME.png} \caption{Der
  prozentuale Anteil einzelner Methoden an der gesamten genutzten Prozessorzeit}
	\label{fig5}
\end{figure}

\chapter{Fehlerbehebungen}

Nummer des Problems | Ursache | Lösung

\paragraph{Issue 16}- \newline
Beschreibung: Es war möglich, Zeilen zu verändern, welche als nicht editierbar angezeigt und festgelegt wurden. Dies geschah, wenn man unterhalb einer solchen Zeile etwas schrieb. Durch Entfernen des Zeilentrennungszeichens wurde dieses Zeichen dann in die nicht editierbare Zeile angehoben.
\newline
Lösung: In die \verb!removeToTheLeft! Methode in \verb!UserInserToCode! wurde ein zusätzlicher Check eingefügt. Es überprüft nun, ob die Zeile über der, in welcher etwas gelöscht wird, nicht editierbar ist. Falls ja, und das zu löschende Zeichen ist ein Zeichentrennungszeichen, wird nur gelöscht, falls die Zeile leer ist, auf welcher sich der Cursor befindet.

\paragraph{Issue 27}- \\
Beschreibung: Obwohl als Voraussetzung angegeben war, dass beide vote-Arrays gleich sein sollten (\verb!VOTES1==VOTES2!) wurden in beiden Wahlvorgängen verschiedene Stimmen abgegeben.\\
Lösung: Der Bug stammte daher, dass der generierte Code die abgegebenen Stimmen nur bis zur Anzahl der Wähler verglich. Bei Wahlverfahren, bei welchen jeder Wähler eine Liste mit Länge der Anzahl von Kandidaten abgibt, wurden daher nur die ersten Stimmen verglichen. Dies führte zu dem Bug, sobald es mehr Kandidaten als Wähler gab.

\paragraph{Issue 28}- \\
Beschreibung: Bei einem Wahlverfahren, welches Preference-Voting als Input verwendet, dauerte es enorm lange eine Eigenschaft zu testen, wenn es mehr Kandidaten als Wähler gab. Bei 6 Wählern und Kandidaten dauerte eine Überprüfung wenige Sekunden. Bei 5 Wählern und 6 Kandidaten war die Überprüfung nach 2 Minuten noch nicht fertig.\\
Lösung: Die Ursache war, dass bei Preference-voting als zusätzliche Voraussetzung alle von einem Wähler abgegebenen Stimmen verschieden sein müssen. Dies liegt daran, dass diese Platzierungen von Wählern repräsentieren. Der Code, welcher produziert wurde, um diese Eigenschaft sicherzustellen, war fehlerhaft.

\paragraph{Issue 42}- \\
Beschreibung: Bei der Codeerzeugung für Vergleiche wurden linke und rechte Seite des Vergleichs vertauscht.\\
Lösung: An der Stelle, an welcher der String für den Vergleich generiert wird, wurde "`lhs"' und "`rhs"' vertauscht. 
 


\chapter{Verbesserungen in der Phase}
Neben Fehlerbehebungen haben wir BEAST in dieser Phase auch in einigen Punkten
verbessert:

\begin{itemize}
  \item Im Eigenschafteneditor gibt es nun einen Knopf, welcher eine Erklärung
  über die BooleanExpressionLanguage gibt, mit der der Nutzer seine Befehle
  schreiben kann.
  \item Der Nutzer kann nun Wähler, Kandidaten und Sitze via ihrer Position in den entsprechenden Arrays angeben. Dazu wurden die Sprachkonstrukte \verb!VOTER_AT_POS!, \verb!CAND_AT_POS! und \verb!SEAT_AT_POS! implementiert.
  \item Der Nutzer kann nun beliebige mathematische Terme angeben, welche *, /, + und - unterstützen. Diese binären mathematischen Operationen können auf sämtliche Ausdrücke angewendet werden, welche einen ganzzahligen Wert liefern.
\end{itemize}

\chapter{Anhang}

\section{Testprotokolle}
\input{testProtokolle/Testfall8_1.tex}
\input{testProtokolle/Testfall8_1b.tex}
\input{testProtokolle/Testfall8_1c.tex}
\input{testProtokolle/Testfall8_2.tex}
\input{testProtokolle/Testfall8_4.tex}
\input{testProtokolle/Testfall8_5.tex}
\input{testProtokolle/Testfall8_6.tex}
\input{testProtokolle/Testfall8_7.tex}
\input{testProtokolle/Testfall8_7b.tex}
\input{testProtokolle/Testfall8_8.tex}


\end{document}